apiVersion: serving.kubeflow.org/v1beta1
kind: InferenceService
metadata:
  name: torchscript-cifar10
  annotations:
    "serving.kubeflow.org/gke-accelerator": "nvidia-tesla-p100"
spec:
  predictor:
    minReplicas: 1
    triton:
      storageUri: gs://kfserving-examples/models/torchscript
      runtimeVersion: "1.14.0-gpu"
      env:
      - name: OMP_NUM_THREADS
        value: "1"
      resources:
        limits:
          nvidia.com/gpu: 1